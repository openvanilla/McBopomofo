# McBopomofo Dictionary Data

This directory contains all dictionary data files and the build system for generating McBopomofo's language model data. These files define the mapping between Bopomofo phonetic input and Traditional Chinese characters/phrases, along with frequency data and special features like macros and symbols.

**For comprehensive dictionary development workflows**, see [Wiki: 詞庫開發說明](https://github.com/openvanilla/McBopomofo/wiki/詞庫開發說明).

**Key Principle:** In most cases, you'll be **adding** new characters or phrases rather than deleting existing ones.

## Directory Structure

```
├── BPMFBase.txt          Single character Bopomofo mappings
├── BPMFMappings.txt      Multi-character phrases (2-6 chars)
│                         Originally simplified from tsi.src of libtabe
│                         (BSD Licensed) with modifications
├── BPMFPunctuations.txt  Punctuation marks
├── heterophony1.list     Heterophony reading priorities (1st order)
├── heterophony2.list     Heterophony reading priorities (2nd order)
├── heterophony3.list     Heterophony reading priorities (3rd order)
├── phrase.occ            Phrase frequency/occurrence data
├── exclusion.txt         Phrase frequency exclusions
├── Symbols.txt           Special symbols (era names, etc.)
├── Macros.txt            Text macros (date/time)
├── Makefile              Build automation
├── pyproject.toml        Python package configuration
├── textpool.rc           Corpus counting configuration
│
├── curation/             Python package for data processing
│   │                     (exports PROJECT_ROOT, CONFIG_FILE for path resolution)
│   ├── builders/         frequency_builder, phrase_deriver
│   ├── compilers/        main_compiler, plain_bpmf_compiler, compiler_utils
│   ├── utils/            text_filter
│   ├── validators/       score_validator, encoding auditor
│   └── notebooks/        Jupyter analysis notebooks
│
├── scripts/              Standalone CLI tools (with side effects)
│   │                     (imports paths from curation package)
│   ├── count_occurrences.py  Count phrase occurrences in corpus
│   ├── analyze_data.py       Analyze dictionary data quality
│   ├── map_bpmf.py           Primitive BPMF mapping helper
│   └── audit_encoding.py     Validate BPMFBase.txt encoding categories
│
├── tests/                Unit tests for curation package
└── memo/                 Reference data and notes
```

## File Descriptions

### Source Data Files (Input)

| File | Purpose | Format |
|------|---------|--------|
| `BPMFBase.txt` | Single character Bopomofo mappings | `character bopomofo pinyin tone tag` |
| `BPMFMappings.txt` | Multi-character phrases (2-6 chars) | `phrase bpmf1 bpmf2 ...` (space-separated) |
| `BPMFPunctuations.txt` | Punctuation marks mapping | Similar to BPMFBase |
| `phrase.occ` | Phrase frequency/occurrence data | `phrase frequency` (tab-separated) |
| `heterophony1.list` | Primary heterophony readings | `character bopomofo` |
| `heterophony2.list` | Secondary heterophony readings | `character bopomofo` |
| `heterophony3.list` | Tertiary heterophony readings | `character bopomofo` |
| `exclusion.txt` | Phrase frequency exclusions | `phrase context_to_exclude` (tab-separated) |
| `Symbols.txt` | Special symbols (era names, etc.) | `symbol bopomofo score` |
| `Macros.txt` | Text macros (date/time) | `MACRO@NAME bopomofo score` |
| `associated-punctuation.txt` | Punctuation for phrase associations | Special format for derive script |

### Generated Output Files

| File | Generated By | Purpose |
|------|--------------|---------|
| `data.txt` | `make all` | Main language model data for McBopomofo |
| `data-plain-bpmf.txt` | `make all` | Data for traditional Bopomofo IME mode |
| `associated-phrases-v2.txt` | `make all` | Associated phrase suggestions |
| `PhraseFreq.txt` | `make all` | Compiled frequency data |

**Important:** Generated output files are built locally and NOT committed to git (listed in `.gitignore`).

## Build System & Commands

### Essential Make Targets

```bash
make all           # Generate all output files
make sort          # Sort all data files with correct C locale
make check         # Validate data integrity
make tidy          # Clean up formatting issues
make clean         # Clean generated files

# Recommended workflow: format, sort, validate, and build
make tidy sort check all
```

### Building via Xcode

```bash
xcodebuild -project ../McBopomofo.xcodeproj -target Data -configuration Debug build
# Or select "Data" scheme in Xcode and build (⌘+B)
```

This runs `make all` as part of the Xcode build process. For dictionary development, using `make` directly is recommended.

### Critical: C Locale Sorting

**All data files MUST be sorted with C locale** for binary search compatibility:

```bash
# Primary data files
LC_ALL=C sort -o BPMFMappings.txt BPMFMappings.txt
LC_ALL=C sort -o phrase.occ phrase.occ

# Heterophony lists
env LANG=C sort -k1 heterophony1.list | uniq > tmp && mv tmp heterophony1.list
env LANG=C sort -k1 heterophony2.list | uniq > tmp && mv tmp heterophony2.list
env LANG=C sort -k1 heterophony3.list | uniq > tmp && mv tmp heterophony3.list
```

## Workflow: Adding/Modifying Phrases

### Adding a New Multi-Character Phrase

1. **Add to BPMFMappings.txt:**
   ```
   新詞彙 ㄒㄧㄣ ㄘˊ ㄏㄨㄟˋ
   ```
   Format: phrase, then Bopomofo for each character (space-separated)

2. **Add to phrase.occ with frequency:**
   ```
   新詞彙	100
   ```
   - Frequency must be a positive integer (0 is acceptable, negative values are NOT)
   - Use tab separator between phrase and frequency
   - Higher frequency = more common phrase

3. **Sort both files:**
   ```bash
   make sort
   # Or manually:
   LC_ALL=C sort -o BPMFMappings.txt BPMFMappings.txt
   LC_ALL=C sort -o phrase.occ phrase.occ
   ```

4. **Validate and build:**
   ```bash
   make check    # Validate integrity
   make all      # Generate output files
   ```

### Adding a Single Character

Single characters go into `BPMFBase.txt`:

```
字 ㄗˋ zi4 -4 big5
```

Format: `character bopomofo pinyin tone tag`

### Handling Heterophony Characters (破音字)

For characters with multiple pronunciations (e.g., 行: ㄏㄤˊ vs ㄒㄧㄥˊ):

1. Place most common reading in `heterophony1.list`, less common in `heterophony2.list`, rare in `heterophony3.list`
2. Add both readings to `BPMFMappings.txt`

Example:
```bash
# heterophony1.list
行 ㄏㄤˊ

# heterophony2.list
行 ㄒㄧㄥˊ
```

### Adding Emojis and Symbols

Emojis/symbols are allowed but **MUST NOT be the default candidate**. Add to `Symbols.txt` with negative score (e.g., `-8`).

## File Format Specifications

| File | Format | Rules | Example |
|------|--------|-------|---------|
| **BPMFMappings.txt** | `phrase bpmf1 bpmf2 ...` | Space-separated; character count = Bopomofo count; C locale sorted | `小麥注音 ㄒㄧㄠˇ ㄇㄞˋ ㄓㄨˋ ㄧㄣ` |
| **phrase.occ** | `phrase<TAB>frequency` | Tab-separated; frequency ≥ 0 (no negatives); C locale sorted | `小麥<TAB>120` |
| **heterophony*.list** | `character bopomofo` | One reading per line; sorted by character | `中 ㄓㄨㄥ` |
| **exclusion.txt** | `phrase<TAB>context` | Tab-separated; excludes phrase when in context | `一下<TAB>國一下` |
| **Symbols.txt** | `symbol bopomofo score` | Space-separated; negative score for low priority | `平成 ㄆㄧㄥˊ-ㄔㄥˊ -8` |
| **Macros.txt** | `MACRO@NAME bopomofo score` | Space-separated; runtime expansion | `MACRO@DATE_TODAY ㄐㄧㄣ-ㄊㄧㄢ -8` |

**Critical Format Rules:**
- BPMFMappings.txt and phrase.occ use **different separators** (space vs tab)
- Character count in phrase must equal number of Bopomofo readings
- Frequencies must be non-negative integers (0 acceptable, negatives NOT allowed)
- All files must be C locale sorted for binary search compatibility

## Python Package Structure

The `curation/` package contains library modules organized into submodules:

| Submodule | Purpose |
|-----------|---------|
| `curation.builders` | Data building and processing tools (frequency_builder, phrase_deriver) |
| `curation.compilers` | Data compilation tools (main_compiler, plain_bpmf_compiler) |
| `curation.validators` | Validation and analysis tools (score_validator) |
| `curation.utils` | General utilities (text_filter) |

Scripts with side effects are located in `scripts/`:

| Script | Purpose |
|--------|---------|
| `count_occurrences.py` | Counts phrase occurrences in text corpus |
| `analyze_data.py` | Analyzes dictionary data and generates reports |
| `map_bpmf.py` | Helper for automatic Bopomofo mapping |
| `audit_encoding.py` | Validates BPMFBase.txt encoding categories (Big5/CNS/UTF-8) |

## Python Development Guidelines

**CRITICAL RULES for AI coding assistants:**

### 1. Module Organization Rules

**Library modules** (in `curation/` package) **MUST NOT** have side effects at module level:
- **PROHIBITED**: Opening files, reading/writing data, printing output at module level
- **PROHIBITED**: Executing code immediately when module is imported
- **REQUIRED**: All initialization must be in functions
- **REQUIRED**: Module must be importable without executing code

**Example of BAD module (violates rules):**
```python
# BAD: Has side effects at import time
import configparser
config = configparser.ConfigParser()
config.read('config.ini')  # WRONG: Reads file at import!
corpus = open('corpus.txt').read()  # WRONG: Opens file at import!
```

**Example of GOOD module:**
```python
# GOOD: No side effects, importable as library
import configparser

def load_config(config_path='config.ini'):
    """Load configuration from file."""
    config = configparser.ConfigParser()
    config.read(config_path)
    return config

def main():
    """Main entry point for CLI usage."""
    config = load_config()
    # ... rest of logic

if __name__ == '__main__':
    main()
```

### 2. Import Guidelines

- **REQUIRED**: All imports at top of file
- **NEVER** use inline imports (unless explicitly necessary for specific technical reasons)
- Use relative imports within package (e.g., `from .compiler_utils import HEADER`)
- Use absolute imports for external packages (e.g., `import argparse`)

**Example of BAD imports:**
```python
# BAD: Inline import
def process_data():
    import pandas as pd  # WRONG: NEVER do this!
    return pd.DataFrame(data)
```

**Example of GOOD imports:**
```python
# GOOD: All imports at top
import argparse
import sys
from typing import List, Dict
from .compiler_utils import HEADER

def process_data(input_data):
    result = []
    for item in input_data:
        result.append(item.upper())
    return result
```

### 3. Code Spacing Rules

**Blank lines between functions/classes (PEP 8 - enforced by Ruff):**
- **2 blank lines** between top-level functions and classes
- **1 blank line** between methods inside classes

**Blank lines within functions (Project rule - not in PEP 8):**
- **Minimize blank lines within function bodies**
- Only use blank lines to separate distinct logical sections
- Do NOT use blank lines after variable declarations
- Do NOT use blank lines before/after control flow statements unless separating major logic blocks

**BAD - Excessive blank lines:**
```python
def process_data(file_path: Path) -> dict:
    data = {}

    with open(file_path) as f:  # Unnecessary blank line above
        for line in f:
            if not line:
                continue

            elements = line.split()  # Unnecessary blank line above

            if len(elements) >= 2:  # Unnecessary blank line above
                data[elements[0]] = elements[1]

    return data  # Unnecessary blank line above
```

**GOOD - Minimal blank lines:**
```python
def process_data(file_path: Path) -> dict:
    data = {}
    with open(file_path) as f:
        for line in f:
            if not line:
                continue
            elements = line.split()
            if len(elements) >= 2:
                data[elements[0]] = elements[1]
    return data
```

**ACCEPTABLE - Blank line for major logical separation:**
```python
def complex_processing(input_data: dict) -> dict:
    result = {}
    for key, value in input_data.items():
        result[key] = transform(value)

    # Blank line OK here - separates validation from processing
    if not validate_result(result):
        raise ValueError("Invalid result")
    return result
```

**Code quality enforcement:**
Run Ruff regularly to catch PEP 8 violations:
```bash
ruff check .
ruff format .
```

### 4. Magic Numbers and Constants

Important constants used throughout the codebase and their rationale.

| Constant | File | Value | Purpose | Rationale |
|----------|------|-------|---------|-----------|
| `FREQUENCY_SCALE` | `curation/builders/frequency_builder.py` | `2.7` | Phrase length normalization factor | Higher values favor longer phrases in scoring. Empirically determined to balance phrase length preference with frequency data for Traditional Chinese input. |
| `UNK_LOG_FREQ` | `curation/compilers/main_compiler.py` | `-99.0` | Unknown phrase log frequency | Represents effectively zero probability (log₁₀ scale). Assigned to unscored phrases to mark them as present but rarely used. |
| `H_DEFLT_FREQ` | `curation/compilers/main_compiler.py` | `-6.8` | Default heterophony frequency | Moderate probability for heterophonic character variants without explicit frequency data. Balances accessibility with avoiding over-suggestion. |
| `INITIAL_SCORE` | `curation/validators/score_validator.py` | `-9999.99` | Sentinel value for score comparison | Used as initial minimum when finding maximum score during phrase segmentation. Any real score will be higher than this sentinel. |

**Notes:**
- All frequency values use base-10 logarithmic scale
- Negative log values represent probabilities less than 1 (standard in NLP)
- Constants are tuned empirically for Traditional Chinese Bopomofo input
- Frequency scale affects trade-off between single characters and multi-character phrases

### 5. Side Effect Management

**Scripts with side effects belong in `scripts/` directory, NOT in `curation/` package.**

Scripts that do any of the following must be in `scripts/`:
- Read configuration files at module level
- Open and process data files at module level
- Print output or generate reports at module level
- Execute analysis immediately when imported

**When to use `scripts/` vs `curation/`:**

| Location | Purpose | Characteristics |
|----------|---------|-----------------|
| `scripts/` | Pure CLI tools | Has side effects; not importable as library; immediate execution |
| `curation/` | Library modules | No side effects; importable; reusable functions |

### 6. Script vs Library Separation

**Library modules** in `curation/` should:
- Provide reusable functions and classes
- Have a `main()` function for CLI usage
- Be declared in `pyproject.toml` `[project.scripts]`
- Follow pattern: `mcbpmf-tool-name = "curation.module:main"`

**Scripts** in `scripts/` should:
- Be standalone executables
- Have all logic in `if __name__ == '__main__':` block
- Be called directly: `python3 scripts/script_name.py`
- NOT be imported by other modules

### 5. PEP-8 Naming Conventions

- Module names: `lowercase_with_underscores.py`
- Function names: `lowercase_with_underscores()`
- Class names: `CapitalizedWords`
- Constants: `UPPERCASE_WITH_UNDERSCORES`

**Examples:**
- GOOD: `frequency_builder.py`, `main_compiler.py`, `text_filter.py`
- BAD: `buildFreq.py`, `nonCJK_filter.py`, `cook-plain-bpmf.py`

### 6. Package Installation

All dependencies are managed in `pyproject.toml`. Install as editable package for development:

**Using uv (recommended - much faster):**
```bash
uv pip install -e .              # Install package (no optional dependencies)
uv pip install -e ".[dev]"       # Install with dev dependencies (pytest, ruff)
uv pip install -e ".[notebook]"  # Install with notebook dependencies (jupyterlab, pandas, etc.)
```

**Using pip:**
```bash
pip install -e .              # Install package (no optional dependencies)
pip install -e ".[dev]"       # Install with dev dependencies (pytest, ruff)
pip install -e ".[notebook]"  # Install with notebook dependencies (jupyterlab, pandas, etc.)
```

After installation, use console scripts:
```bash
mcbpmf-build-freq              # Instead of: python3 -m curation.builders.frequency_builder
mcbpmf-compile                 # Instead of: python3 -m curation.compilers.main_compiler
mcbpmf-validate-scores         # Instead of: python3 -m curation.validators.score_validator
mcbpmf_audit_encoding          # Encoding validation tool
```

### Console Scripts Reference

Complete list of available CLI tools after `pip install -e .`:

| Command | Module | Purpose |
|---------|--------|---------|
| `mcbpmf-compile` | `curation.compilers.main_compiler` | Build data.txt from all sources |
| `mcbpmf-compile-plain` | `curation.compilers.plain_bpmf_compiler` | Build data-plain-bpmf.txt |
| `mcbpmf-build-freq` | `curation.builders.frequency_builder` | Generate PhraseFreq.txt |
| `mcbpmf-derive-phrases` | `curation.builders.phrase_deriver` | Generate associated phrases |
| `mcbpmf-validate-scores` | `curation.validators.score_validator` | Validate dictionary quality |
| `mcbpmf-filter-non-cjk` | `curation.utils.text_filter` | Filter non-CJK characters |
| `mcbpmf-audit-encoding` | `scripts.audit_encoding` | Validate encoding categories |

### Running Tests

For Python package development:

```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=curation

# Run specific test file
pytest tests/test_specific.py
```

### Code Quality Tools

This project uses Ruff for linting and formatting Python code. Ruff is an extremely fast Python linter and formatter written in Rust.

```bash
# Check code quality (linting)
ruff check .

# Auto-fix issues where possible
ruff check --fix .

# Format code
ruff format .

# Run both linting and formatting
ruff check --fix . && ruff format .
```

**Configuration** is in `pyproject.toml`:
- Line length: 100 characters
- Target: Python 3.12+
- Selected rules: Error detection (E), PEP 8 (F), import sorting (I), naming (N), Python upgrades (UP), bugbear (B), comprehensions (C4), simplify (SIM)

### Jupyter Notebooks

The `curation/notebooks/` directory contains analysis tools:

- `playground.ipynb` - Term score verification and data analysis

To use notebooks:
```bash
uv pip install -e ".[notebook]"  # or: pip install -e ".[notebook]"
jupyter notebook curation/notebooks/
```

### Example Module Pattern

When creating new modules in the `curation/` package, follow this pattern:

```python
#!/usr/bin/env python3
import argparse
from pathlib import Path
from curation import PROJECT_ROOT

def process_data(input_file: Path) -> None:
    """Process dictionary data."""
    # Implementation here
    pass

def main():
    """CLI entry point."""
    parser = argparse.ArgumentParser()
    parser.add_argument('input', type=Path)
    args = parser.parse_args()
    process_data(args.input)

if __name__ == '__main__':
    main()
```

## Project Path Configuration

All scripts and modules use centralized path constants from the `curation` package:

```python
from curation import PROJECT_ROOT, CONFIG_FILE

# PROJECT_ROOT = Source/Data/ directory (where pyproject.toml lives)
# CONFIG_FILE = Source/Data/textpool.rc

# Example usage in scripts
config = configparser.ConfigParser()
config.read(CONFIG_FILE)
corpus_path = Path(config.get('data', 'corpus_path')).expanduser()
```

**Do NOT** compute paths relatively in individual scripts:
- BAD: `Path(__file__).parent.parent`
- BAD: `os.path.abspath(sys.argv[0]).split('/')`
- GOOD: `from curation import PROJECT_ROOT`

This ensures:
- Single source of truth for project structure
- Easy refactoring if directory structure changes
- Consistent behavior across all tools

## Data Generation Pipeline

The build process flows: `phrase.occ` + `exclusion.txt` → `buildFreq.py` → `PhraseFreq.txt` → `cook.py` (+ other inputs) → `data.txt` → `derive_associated_phrases.py` → `associated-phrases-v2.txt`.

For detailed pipeline diagram, frequency calculation algorithms, and heterophony processing logic, see `../algorithm.md` section "字典資料的生成與使用".

## Editorial Guidelines

For editorial policies, see [Wiki: 詞庫開發說明](https://github.com/openvanilla/McBopomofo/wiki/詞庫開發說明).

### Phrase Quality Control

When in doubt, use Google/Yahoo search to confirm the rarity of phrases:

```
Example search: "一瞻丰采" site:.tw
```

Check phrase rarity: `site:.tw "phrase"` (under 1,000 results → likely safe to remove)

**Removal criteria:**
- If results are under 1,000, it's likely safe to remove the phrase
- If tsi.src variants show up on first page (SEO sites), remove the phrase
- For idioms, first hit may be idiom database - use editorial judgment
- If candidate is part of a longer phrase with incorrect segmentation, replace with complete phrase (if ≤6 characters)

**Remember:** IME is not an idiom database.

### Data Integrity Checks

```bash
# Character count matches Bopomofo count (empty output = good)
awk 'length($1)/3!=NF-1' BPMFMappings.txt

# Phrase consistency check
diff -u <(awk '{print $1}' BPMFMappings.txt|sort -u) \
        <(awk 'length($1)>3{print $1}' phrase.occ|sort -u)
```

## Testing Your Changes

```bash
make tidy sort    # Format and sort
make check        # Validate integrity
make all          # Build output files
make _install     # Install to ~/Library/Input Methods/McBopomofo.app/
pkill -HUP McBopomofo  # Restart
```

## Common Issues and Solutions

| Issue | Solution |
|-------|----------|
| Sort order is wrong | Always use C locale: `LC_ALL=C sort -o file file` |
| Phrase in BPMFMappings.txt not showing | Verify phrase exists in `phrase.occ` with non-zero frequency |
| make check fails (character count) | Ensure character count = Bopomofo reading count |
| Heterophony shows wrong default | Place common reading in `heterophony1.list`, less common in `heterophony2.list` |
| Emoji appears as first candidate | Add to `Symbols.txt` with negative score (e.g., -8) |

## Tool Evolution History (2012-2025)

### Phase 1: Multi-Language Era (2005-2012)
- Original tools in Perl, Ruby, Bash
- Multiple implementations for different purposes

### Phase 2: Python Migration (2012-2013)
- **2012-08-06**: `cook.py` replaced Ruby implementation (Mengjuei Hsieh)
- **2012-09-16**: `buildFreq.py` replaced bash version (Mengjuei Hsieh)
- **2013-01-02**: `self-score-test.py` added for quality validation (Mengjuei Hsieh)
- **2013-01-21**: C version moved to subdirectory, Python became primary

### Phase 3: Maturation (2014-2023)
- Tools stable and functional
- Minor updates for Python 3 compatibility
- **2022-01-18**: Copyright header updates (Lukhnos Liu)
- **2022-12-30**: count.occurrence.py updates (Mengjuei Hsieh)

### Phase 4: Modern Features (2024)
- **2024-03-15**: Associated phrases v2 system (Lukhnos Liu)
- **2024-08-25**: Swift encoding audit tool (zonble)
- **2024-10-30**: Enhanced associated phrases with punctuation (zonble)

### Phase 5: Package Reorganization (2024-2025)
- **October 2024**: Migration to `curation/` package structure
- **2025-03-08**: Final modernization - Black formatting (Lukhnos Liu)
- **2025-03-08**: argparse refactor (Lukhnos Liu)
- **January 2025**: Complete Python 3 migration, legacy cleanup

**Benefits achieved:**
- Proper Python package with PEP-8 compliance
- Organized submodules (builders, compilers, validators, utils)
- Importable modules without side effects
- Package installation via pyproject.toml
- Console script entry points
- Centralized path configuration

### Migration Summary

**What was migrated:**
- All compilation and build tools → `curation/` package
- Frequency calculation → `curation.builders`
- Data validation → `curation.validators`
- Text processing utilities → `curation.utils`
- Corpus occurrence counting → `scripts/`
- Data analysis reports → `scripts/`
- BPMF mapping helpers → `scripts/`

**Path configuration changed:**
- **Before**: Each script calculated paths relatively
- **After**: Import from `curation` package: `from curation import PROJECT_ROOT, CONFIG_FILE`

## Key Contributors

- **Mengjuei Hsieh**: Original Python implementation (2012-2013), corpus processing tools
- **Lukhnos Liu**: Modernization, associated phrases v2, package reorganization (2024-2025)
- **zonble**: Encoding audit tools, enhanced features (2024)

## References

- **Project Overview**: `../../AGENTS.md` - McBopomofo project architecture and build system
- **Algorithm Details**: `../algorithm.md` - Data generation pipeline and methodology
- **Main Documentation**: `../../README.markdown` - Main project documentation
- **Wiki: 程式架構**: Program architecture (https://github.com/openvanilla/McBopomofo/wiki/程式架構)
- **Wiki: 詞庫開發說明**: Dictionary development guide (https://github.com/openvanilla/McBopomofo/wiki/詞庫開發說明)
- **Wiki: 使用手冊**: User manual (https://github.com/openvanilla/McBopomofo/wiki/使用手冊)
